{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de treinamento e validação salvos em ./data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_176427/271170338.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(X_train, dtype=torch.float32).clone().detach()\n",
      "/tmp/ipykernel_176427/271170338.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train_tensor = torch.tensor(y_train, dtype=torch.float32).clone().detach()\n",
      "/tmp/ipykernel_176427/271170338.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val_tensor = torch.tensor(X_val, dtype=torch.float32).clone().detach()\n",
      "/tmp/ipykernel_176427/271170338.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_val_tensor = torch.tensor(y_val, dtype=torch.float32).clone().detach()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Criar pasta para armazenar os dados\n",
    "data_dir = \"./data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Carregar o dataset\n",
    "dataset = pd.read_excel(\"Server_1_Training_Sets/datasets/cpu_usage_1-13.xlsx\")\n",
    "#dataset = pd.read_excel(\"Server_1_Training_Sets/datasets/ram_usage_1-13.xlsx\")\n",
    "# dataset = pd.read_excel(\"Server_1_Training_Sets/network_usage_1-13.xlsx\")\n",
    "\n",
    "# Preparar os dados\n",
    "X_columns = dataset.columns[:len(dataset.columns)-1]\n",
    "X = np.array(dataset[X_columns]).reshape(-len(X_columns), len(X_columns))\n",
    "y = np.array(dataset[\"y\"]).reshape(-1, 1)\n",
    "\n",
    "X_data = torch.tensor(X, dtype=torch.float32)\n",
    "y_data = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Dividir os dados em treino e validação\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.1, random_state=2024, shuffle=True)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).clone().detach()\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).clone().detach()\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32).clone().detach()\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).clone().detach()\n",
    "\n",
    "# Salvar os dados em disco\n",
    "torch.save((X_train, y_train), os.path.join(data_dir, \"train_data.pt\"))\n",
    "torch.save((X_val, y_val), os.path.join(data_dir, \"val_data.pt\"))\n",
    "\n",
    "print(f\"Dados de treinamento e validação salvos em {data_dir}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_176427/3803462038.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.X, self.y = torch.load(data_path)\n"
     ]
    }
   ],
   "source": [
    "# Criar uma classe customizada para o dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        self.X, self.y = torch.load(data_path)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Carregar os dados com DataLoader\n",
    "train_dataset = CustomDataset(os.path.join(data_dir, \"train_data.pt\"))\n",
    "val_dataset = CustomDataset(os.path.join(data_dir, \"val_data.pt\"))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checagem do train test split\n",
    "# Verifica se uma das amostras separadas para o X_train e y_train é compatível com o conjunto de dados original \"dataset\"\n",
    "\n",
    "dataset_sample = list(X_train[0]) + list(y_train[0])\n",
    "\n",
    "# Checagem do CustomDataset\n",
    "# Verifica se uma das amostras separadas para o PyTorch CustomDataset é compatível com o conjunto de dados original \"dataset\"\n",
    "\n",
    "xysample = list(train_dataset.__getitem__(0)[0]) + list(train_dataset.__getitem__(0)[1])\n",
    "\n",
    "# Checagem do DataLoader\n",
    "# Verifica se uma das amostras separadas para o Dataloader é compatível com o conjunto de dados original \"dataset\"\n",
    "next_train_loader_sample = next(iter(train_loader))\n",
    "dataloader_xysample = next_train_loader_sample[0][0].tolist() + next_train_loader_sample[1][0].tolist()\n",
    "\n",
    "assert len(dataset[(dataset[dataset.columns] == xysample).all(axis=1)].index) >= 1\n",
    "assert len(dataset[(dataset[dataset.columns] == xysample).all(axis=1)].index) >= 1\n",
    "assert len(dataset[(dataset[dataset.columns] == dataset_sample).all(axis=1)].index) >= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "import os\n",
    "\n",
    "'''class SimpleLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = 256\n",
    "        self.num_layers = 3\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=40, hidden_size=self.hidden_size, num_layers=self.num_layers, batch_first=True, bidirectional=True)\n",
    "        self.linear = nn.Linear(2 * self.hidden_size, 1)\n",
    "        #self.linear = nn.Linear(self.hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x)\n",
    "        #x = self.linear(x[:, -1, :])  # Apenas a última saída do LSTM\n",
    "        return x'''\n",
    "    \n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = 256\n",
    "        self.num_layers = 3\n",
    "        self.lstm = nn.LSTM(input_size=40, hidden_size=self.hidden_size, num_layers=self.num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(self.hidden_size, 1)  # Ajustado para LSTM unidirecional\n",
    "\n",
    "        #self.linear1 = nn.Linear(40, 30)\n",
    "        #self.relu1 = nn.ReLU()\n",
    "        #self.linear2 = nn.Linear(30, 20)\n",
    "        #self.relu2 = nn.ReLU()\n",
    "        #self.linear3 = nn.Linear(20, 10)\n",
    "        #self.relu3 = nn.ReLU()\n",
    "        #self.linear4 = nn.Linear(10, 1)\n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Garantir que a entrada tenha 3 dimensões\n",
    "        x, _ = self.lstm(x)  # x: (batch_size, seq_length, hidden_size)\n",
    "        x = self.linear(x)  # Apenas a última saída da sequência\n",
    "\n",
    "        #x = self.linear1(x)\n",
    "        #x = self.relu1(x)\n",
    "        #x = self.linear2(x)\n",
    "        #x = self.relu2(x)\n",
    "        #x = self.linear3(x)\n",
    "        #x = self.relu3(x)\n",
    "        #x = self.linear4(x)\n",
    "        #x = self.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def train(model, optimizer, loss_fn, device, n_epochs, max_consecutive_increases):\n",
    "    global train_rmse_history\n",
    "    global val_rmse_history\n",
    "\n",
    "    best_rmse = float('inf')\n",
    "    best_epoch = 0\n",
    "    consecutive_increases = 0\n",
    "\n",
    "    train_rmse_history = []\n",
    "    val_rmse_history = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()  # Certifique-se de que o modelo está em modo de treinamento\n",
    "        train_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * X_batch.size(0)  # Acumula a loss total ponderada pelo tamanho do batch\n",
    "        \n",
    "        # Calcular RMSE de treino médio para a época\n",
    "        train_rmse = np.sqrt(train_loss / len(train_loader.dataset))\n",
    "\n",
    "        # Avaliação no conjunto de validação\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():  # Desabilita o cálculo de gradientes\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                y_pred = model(X_batch)\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                val_loss += loss.item() * X_batch.size(0)  # Acumula a loss total ponderada pelo tamanho do batch\n",
    "        \n",
    "        # Calcular RMSE de validação médio para a época\n",
    "        val_rmse = np.sqrt(val_loss / len(val_loader.dataset))\n",
    "        \n",
    "        # Salvar histórico de RMSE\n",
    "        train_rmse_history.append(train_rmse)\n",
    "        val_rmse_history.append(val_rmse)\n",
    "        \n",
    "        # Printar os resultados da época\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}: train RMSE {train_rmse:.4f}, val RMSE {val_rmse:.4f}\")\n",
    "        \n",
    "        if val_rmse < best_rmse:\n",
    "            best_rmse = val_rmse\n",
    "            best_epoch = epoch\n",
    "            checkpoint_path = f\"models/model_best_rmse.pt\"\n",
    "            torch.save(model, checkpoint_path)\n",
    "            print(f\"Modelo salvo com RMSE: {best_rmse} na época {epoch}\")\n",
    "        \n",
    "        with open(\"models/performance.txt\", \"w\") as f:\n",
    "            f.write(f\"Best Model Val RMSE: {best_rmse}\\nModel Best Val Epoch: {best_epoch}\\nModel Train RMSE History: {train_rmse_history}\\nModel Val RMSE History: {val_rmse_history}\")\n",
    "\n",
    "        if len(val_rmse_history) > 1 and val_rmse > val_rmse_history[-2]:\n",
    "            consecutive_increases += 1\n",
    "        else:\n",
    "            consecutive_increases = 0\n",
    "        \n",
    "        if consecutive_increases >= max_consecutive_increases:\n",
    "            print(f\"Early stopping at epoch {epoch} due to consecutive increases in RMSE.\")\n",
    "            break\n",
    "        \n",
    "    print(f\"Melhor RMSE encontrado: {best_rmse} na época {best_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: train RMSE 0.1619, val RMSE 0.0451\n",
      "Modelo salvo com RMSE: 0.045121141626541086 na época 0\n",
      "Epoch 2/100: train RMSE 0.0438, val RMSE 0.0434\n",
      "Modelo salvo com RMSE: 0.043407717576865394 na época 1\n",
      "Epoch 3/100: train RMSE 0.0418, val RMSE 0.0411\n",
      "Modelo salvo com RMSE: 0.04114491229387079 na época 2\n",
      "Epoch 4/100: train RMSE 0.0394, val RMSE 0.0383\n",
      "Modelo salvo com RMSE: 0.03826570986259798 na época 3\n",
      "Epoch 5/100: train RMSE 0.0360, val RMSE 0.0345\n",
      "Modelo salvo com RMSE: 0.03452984269871815 na época 4\n",
      "Epoch 6/100: train RMSE 0.0324, val RMSE 0.0313\n",
      "Modelo salvo com RMSE: 0.03133420731334361 na época 5\n",
      "Epoch 7/100: train RMSE 0.0306, val RMSE 0.0301\n",
      "Modelo salvo com RMSE: 0.03013293817790016 na época 6\n",
      "Epoch 8/100: train RMSE 0.0300, val RMSE 0.0304\n",
      "Epoch 9/100: train RMSE 0.0300, val RMSE 0.0302\n",
      "Epoch 10/100: train RMSE 0.0300, val RMSE 0.0303\n",
      "Epoch 11/100: train RMSE 0.0300, val RMSE 0.0298\n",
      "Modelo salvo com RMSE: 0.029787855746308774 na época 10\n",
      "Epoch 12/100: train RMSE 0.0299, val RMSE 0.0298\n",
      "Epoch 13/100: train RMSE 0.0299, val RMSE 0.0319\n",
      "Epoch 14/100: train RMSE 0.0300, val RMSE 0.0298\n",
      "Modelo salvo com RMSE: 0.02978683573138423 na época 13\n",
      "Epoch 15/100: train RMSE 0.0298, val RMSE 0.0301\n",
      "Epoch 16/100: train RMSE 0.0300, val RMSE 0.0307\n",
      "Epoch 17/100: train RMSE 0.0300, val RMSE 0.0298\n",
      "Epoch 18/100: train RMSE 0.0299, val RMSE 0.0298\n",
      "Epoch 19/100: train RMSE 0.0300, val RMSE 0.0301\n",
      "Epoch 20/100: train RMSE 0.0302, val RMSE 0.0298\n",
      "Epoch 21/100: train RMSE 0.0300, val RMSE 0.0298\n",
      "Modelo salvo com RMSE: 0.029772249211858847 na época 20\n",
      "Epoch 22/100: train RMSE 0.0298, val RMSE 0.0304\n",
      "Epoch 23/100: train RMSE 0.0300, val RMSE 0.0301\n",
      "Epoch 24/100: train RMSE 0.0300, val RMSE 0.0310\n",
      "Epoch 25/100: train RMSE 0.0301, val RMSE 0.0309\n",
      "Epoch 26/100: train RMSE 0.0302, val RMSE 0.0297\n",
      "Modelo salvo com RMSE: 0.029746243212960488 na época 25\n",
      "Epoch 27/100: train RMSE 0.0300, val RMSE 0.0299\n",
      "Epoch 28/100: train RMSE 0.0299, val RMSE 0.0297\n",
      "Modelo salvo com RMSE: 0.02974519812040516 na época 27\n",
      "Epoch 29/100: train RMSE 0.0300, val RMSE 0.0309\n",
      "Epoch 30/100: train RMSE 0.0299, val RMSE 0.0299\n",
      "Epoch 31/100: train RMSE 0.0300, val RMSE 0.0301\n",
      "Epoch 32/100: train RMSE 0.0301, val RMSE 0.0312\n",
      "Epoch 33/100: train RMSE 0.0302, val RMSE 0.0298\n",
      "Epoch 34/100: train RMSE 0.0301, val RMSE 0.0304\n",
      "Epoch 35/100: train RMSE 0.0301, val RMSE 0.0300\n",
      "Epoch 36/100: train RMSE 0.0299, val RMSE 0.0297\n",
      "Modelo salvo com RMSE: 0.029742093171008396 na época 35\n",
      "Epoch 37/100: train RMSE 0.0300, val RMSE 0.0300\n",
      "Epoch 38/100: train RMSE 0.0300, val RMSE 0.0297\n",
      "Modelo salvo com RMSE: 0.02973582308311863 na época 37\n",
      "Epoch 39/100: train RMSE 0.0299, val RMSE 0.0297\n",
      "Modelo salvo com RMSE: 0.029690724750076912 na época 38\n",
      "Epoch 40/100: train RMSE 0.0300, val RMSE 0.0310\n",
      "Epoch 41/100: train RMSE 0.0300, val RMSE 0.0299\n",
      "Epoch 42/100: train RMSE 0.0299, val RMSE 0.0307\n",
      "Epoch 43/100: train RMSE 0.0301, val RMSE 0.0330\n",
      "Epoch 44/100: train RMSE 0.0306, val RMSE 0.0297\n",
      "Epoch 45/100: train RMSE 0.0302, val RMSE 0.0297\n",
      "Epoch 46/100: train RMSE 0.0299, val RMSE 0.0300\n",
      "Epoch 47/100: train RMSE 0.0300, val RMSE 0.0297\n",
      "Epoch 48/100: train RMSE 0.0299, val RMSE 0.0304\n",
      "Epoch 49/100: train RMSE 0.0301, val RMSE 0.0298\n",
      "Epoch 50/100: train RMSE 0.0301, val RMSE 0.0298\n",
      "Epoch 51/100: train RMSE 0.0299, val RMSE 0.0296\n",
      "Modelo salvo com RMSE: 0.029610239213746302 na época 50\n",
      "Epoch 52/100: train RMSE 0.0301, val RMSE 0.0303\n",
      "Epoch 53/100: train RMSE 0.0299, val RMSE 0.0296\n",
      "Epoch 54/100: train RMSE 0.0302, val RMSE 0.0297\n",
      "Epoch 55/100: train RMSE 0.0297, val RMSE 0.0298\n",
      "Epoch 56/100: train RMSE 0.0297, val RMSE 0.0299\n",
      "Epoch 57/100: train RMSE 0.0299, val RMSE 0.0314\n",
      "Epoch 58/100: train RMSE 0.0300, val RMSE 0.0325\n",
      "Epoch 59/100: train RMSE 0.0298, val RMSE 0.0305\n",
      "Epoch 60/100: train RMSE 0.0297, val RMSE 0.0304\n",
      "Epoch 61/100: train RMSE 0.0299, val RMSE 0.0306\n",
      "Epoch 62/100: train RMSE 0.0302, val RMSE 0.0305\n",
      "Epoch 63/100: train RMSE 0.0297, val RMSE 0.0299\n",
      "Epoch 64/100: train RMSE 0.0299, val RMSE 0.0297\n",
      "Epoch 65/100: train RMSE 0.0298, val RMSE 0.0307\n",
      "Epoch 66/100: train RMSE 0.0300, val RMSE 0.0295\n",
      "Modelo salvo com RMSE: 0.029533316100353327 na época 65\n",
      "Epoch 67/100: train RMSE 0.0297, val RMSE 0.0297\n",
      "Epoch 68/100: train RMSE 0.0297, val RMSE 0.0295\n",
      "Modelo salvo com RMSE: 0.02951947399914504 na época 67\n",
      "Epoch 69/100: train RMSE 0.0297, val RMSE 0.0297\n",
      "Epoch 70/100: train RMSE 0.0298, val RMSE 0.0296\n",
      "Epoch 71/100: train RMSE 0.0298, val RMSE 0.0309\n",
      "Epoch 72/100: train RMSE 0.0298, val RMSE 0.0295\n",
      "Modelo salvo com RMSE: 0.029493877682541848 na época 71\n",
      "Epoch 73/100: train RMSE 0.0298, val RMSE 0.0296\n",
      "Epoch 74/100: train RMSE 0.0297, val RMSE 0.0297\n",
      "Epoch 75/100: train RMSE 0.0298, val RMSE 0.0305\n",
      "Epoch 76/100: train RMSE 0.0299, val RMSE 0.0313\n",
      "Epoch 77/100: train RMSE 0.0298, val RMSE 0.0300\n",
      "Epoch 78/100: train RMSE 0.0296, val RMSE 0.0294\n",
      "Modelo salvo com RMSE: 0.029410066721831538 na época 77\n",
      "Epoch 79/100: train RMSE 0.0295, val RMSE 0.0295\n",
      "Epoch 80/100: train RMSE 0.0295, val RMSE 0.0294\n",
      "Modelo salvo com RMSE: 0.029399923505868317 na época 79\n",
      "Epoch 81/100: train RMSE 0.0294, val RMSE 0.0311\n",
      "Epoch 82/100: train RMSE 0.0297, val RMSE 0.0293\n",
      "Modelo salvo com RMSE: 0.02925489088246939 na época 81\n",
      "Epoch 83/100: train RMSE 0.0292, val RMSE 0.0300\n",
      "Epoch 84/100: train RMSE 0.0295, val RMSE 0.0295\n",
      "Epoch 85/100: train RMSE 0.0291, val RMSE 0.0291\n",
      "Modelo salvo com RMSE: 0.029071579421843883 na época 84\n",
      "Epoch 86/100: train RMSE 0.0295, val RMSE 0.0289\n",
      "Modelo salvo com RMSE: 0.028906324571142727 na época 85\n",
      "Epoch 87/100: train RMSE 0.0292, val RMSE 0.0288\n",
      "Modelo salvo com RMSE: 0.02877800475088438 na época 86\n",
      "Epoch 88/100: train RMSE 0.0291, val RMSE 0.0294\n",
      "Epoch 89/100: train RMSE 0.0292, val RMSE 0.0287\n",
      "Modelo salvo com RMSE: 0.028719588805388968 na época 88\n",
      "Epoch 90/100: train RMSE 0.0289, val RMSE 0.0300\n",
      "Epoch 91/100: train RMSE 0.0290, val RMSE 0.0291\n",
      "Epoch 92/100: train RMSE 0.0286, val RMSE 0.0286\n",
      "Modelo salvo com RMSE: 0.028612903609720394 na época 91\n",
      "Epoch 93/100: train RMSE 0.0290, val RMSE 0.0288\n",
      "Epoch 94/100: train RMSE 0.0287, val RMSE 0.0295\n",
      "Epoch 95/100: train RMSE 0.0288, val RMSE 0.0290\n",
      "Epoch 96/100: train RMSE 0.0289, val RMSE 0.0285\n",
      "Modelo salvo com RMSE: 0.02854814563366379 na época 95\n",
      "Epoch 97/100: train RMSE 0.0286, val RMSE 0.0284\n",
      "Modelo salvo com RMSE: 0.02842655414027338 na época 96\n",
      "Epoch 98/100: train RMSE 0.0287, val RMSE 0.0284\n",
      "Modelo salvo com RMSE: 0.02838010764858103 na época 97\n",
      "Epoch 99/100: train RMSE 0.0287, val RMSE 0.0294\n",
      "Epoch 100/100: train RMSE 0.0287, val RMSE 0.0284\n",
      "Melhor RMSE encontrado: 0.02838010764858103 na época 97\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "model = SimpleLSTM()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "n_epochs = 100\n",
    "max_consecutive_increases = 10\n",
    "\n",
    "train(model, optimizer, loss_fn, device, n_epochs, max_consecutive_increases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metric_name = \"CPU Usage\"\n",
    "#metric_name = \"RAM Usage\"\n",
    "#metric_name = \"Network Usage\"\n",
    "#metric_name = \"Resource Usage\"\n",
    "model_name = \"LSTM\"\n",
    "\n",
    "plt.plot(train_rmse_history)\n",
    "plt.title(f\"{metric_name} - {model_name} - Train RMSE Evolution\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "#plt.show()\n",
    "plt.savefig(f\"plots/{metric_name} {model_name}.png\", dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mwml-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
